{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS = [\"crim\", \"zn\", \"indus\", \"nox\", \"rm\", \"age\",\n",
    "           \"dis\", \"tax\", \"ptratio\", \"medv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_csv('/Users/wisdom/Downloads/boston_train/boston_train.csv', skipinitialspace=True, skiprows=1, names=COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         crim    zn  indus    nox     rm   age     dis  tax  ptratio  medv\n",
      "0     2.30040   0.0  19.58  0.605  6.319  96.1  2.1000  403     14.7  23.8\n",
      "1    13.35980   0.0  18.10  0.693  5.887  94.7  1.7821  666     20.2  12.7\n",
      "2     0.12744   0.0   6.91  0.448  6.770   2.9  5.7209  233     17.9  26.6\n",
      "3     0.15876   0.0  10.81  0.413  5.961  17.5  5.2873  305     19.2  21.7\n",
      "4     0.03768  80.0   1.52  0.404  7.274  38.3  7.3090  329     12.6  34.6\n",
      "..        ...   ...    ...    ...    ...   ...     ...  ...      ...   ...\n",
      "395   0.23912   0.0   9.69  0.585  6.019  65.3  2.4091  391     19.2  21.2\n",
      "396   0.04560   0.0  13.89  0.550  5.888  56.0  3.1121  276     16.4  23.3\n",
      "397   1.38799   0.0   8.14  0.538  5.950  82.0  3.9900  307     21.0  13.2\n",
      "398   7.36711   0.0  18.10  0.679  6.193  78.1  1.9356  666     20.2  11.0\n",
      "399   0.14150   0.0   6.91  0.448  6.169   6.6  5.7209  233     17.9  25.3\n",
      "\n",
      "[400 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv('/Users/wisdom/Downloads/boston_train/boston_test.csv', skipinitialspace=True, skiprows=1, names=COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        crim    zn  indus    nox     rm   age     dis  tax  ptratio  medv\n",
      "0    0.13587   0.0  10.59  0.489  6.064  59.1  4.2392  277     18.6  24.4\n",
      "1    0.08664  45.0   3.44  0.437  7.178  26.3  6.4798  398     15.2  36.4\n",
      "2    0.26938   0.0   9.90  0.544  6.266  82.8  3.2628  304     18.4  21.6\n",
      "3    0.05302   0.0   3.41  0.489  7.079  63.1  3.4145  270     17.8  28.7\n",
      "4    0.06860   0.0   2.89  0.445  7.416  62.5  3.4952  276     18.0  33.2\n",
      "..       ...   ...    ...    ...    ...   ...     ...  ...      ...   ...\n",
      "95   0.13262   0.0   8.56  0.520  5.851  96.7  2.1069  384     20.9  19.5\n",
      "96   6.80117   0.0  18.10  0.713  6.081  84.4  2.7175  666     20.2  20.0\n",
      "97  12.80230   0.0  18.10  0.740  5.854  96.6  1.8956  666     20.2  10.8\n",
      "98  10.23300   0.0  18.10  0.614  6.185  96.7  2.1705  666     20.2  14.6\n",
      "99   0.35809   0.0   6.20  0.507  6.951  88.5  2.8617  307     17.4  26.7\n",
      "\n",
      "[100 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_set = pd.read_csv('/Users/wisdom/Downloads/boston_train/boston_predict.csv', skipinitialspace=True, skiprows=1, names=COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      crim    zn  indus    nox     rm   age     dis  tax  ptratio  medv\n",
      "0  0.03359  75.0   2.95  0.428  7.024  15.8  5.4011  252     18.3   NaN\n",
      "1  5.09017   0.0  18.10  0.713  6.297  91.8  2.3682  666     20.2   NaN\n",
      "2  0.12650  25.0   5.13  0.453  6.762  43.4  7.9809  284     19.7   NaN\n",
      "3  0.05515  33.0   2.18  0.472  7.236  41.1  4.0220  222     18.4   NaN\n",
      "4  8.15174   0.0  18.10  0.700  5.390  98.9  1.7281  666     20.2   NaN\n",
      "5  0.24522   0.0   9.90  0.544  5.782  71.7  4.0317  304     18.4   NaN\n"
     ]
    }
   ],
   "source": [
    "print(prediction_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES =[\"crim\", \"zn\", \"indus\", \"nox\", \"rm\", \"age\",\"dis\", \"tax\", \"ptratio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL=\"medv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [tf.feature_column.numeric_column(k) for k in FEATURES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NumericColumn(key='crim', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='zn', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='indus', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='nox', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='rm', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='dis', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='tax', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='ptratio', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "print(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to get feature cols for features that are variable\n",
    "# CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck',\n",
    "#                        'embark_town', 'alone']\n",
    "# NUMERIC_COLUMNS = ['age', 'fare']\n",
    "\n",
    "# feature_columns = []\n",
    "# for feature_name in CATEGORICAL_COLUMNS:\n",
    "#   vocabulary = dftrain[feature_name].unique()\n",
    "#   feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n",
    "\n",
    "# for feature_name in NUMERIC_COLUMNS:\n",
    "#   feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'train', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa1b9dd3210>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "estimator = tf.estimator.LinearRegressor(feature_columns=feature_cols, model_dir=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_fn(data_set, num_epochs=None, batch_size=128, shuffle=True, steps=1000):\n",
    "    def input_function():\n",
    "        ds = tf.data.Dataset.from_tensor_slices(({k: data_set[k].values for k in FEATURES}, data_set[LABEL]))\n",
    "        if shuffle:\n",
    "            ds = ds.shuffle(steps)\n",
    "        ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "        return ds\n",
    "    return input_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/wisdom/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /Users/wisdom/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:From /Users/wisdom/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:518: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /Users/wisdom/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/canned/linear.py:308: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /Users/wisdom/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/ftrl.py:143: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from train/model.ckpt-5000\n",
      "WARNING:tensorflow:From /Users/wisdom/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into train/model.ckpt.\n",
      "INFO:tensorflow:loss = 61.531536, step = 5000\n",
      "INFO:tensorflow:global_step/sec: 195.707\n",
      "INFO:tensorflow:loss = 61.401146, step = 5100 (0.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.359\n",
      "INFO:tensorflow:loss = 61.276825, step = 5200 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.009\n",
      "INFO:tensorflow:loss = 61.158237, step = 5300 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.296\n",
      "INFO:tensorflow:loss = 61.045105, step = 5400 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.584\n",
      "INFO:tensorflow:loss = 60.9371, step = 5500 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 423.223\n",
      "INFO:tensorflow:loss = 60.834, step = 5600 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 416.83\n",
      "INFO:tensorflow:loss = 60.73552, step = 5700 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 404.354\n",
      "INFO:tensorflow:loss = 60.641434, step = 5800 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 401.984\n",
      "INFO:tensorflow:loss = 60.55153, step = 5900 (0.249 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into train/model.ckpt.\n",
      "WARNING:tensorflow:From /Users/wisdom/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:Loss for final step: 29.14812.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearRegressorV2 at 0x7fa1d44fae10>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.train(input_fn=get_input_fn(training_set,                                       \n",
    "                                           num_epochs=None,                                      \n",
    "                                           batch_size = 128,                                      \n",
    "                                           shuffle=False),                                      \n",
    "                                           steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-01-02T01:41:10Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from train/model.ckpt-6000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2021-01-02-01:41:10\n",
      "INFO:tensorflow:Saving dict for global step 6000: average_loss = 21.846708, global_step = 6000, label/mean = 22.08, loss = 21.846708, prediction/mean = 23.950424\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6000: train/model.ckpt-6000\n"
     ]
    }
   ],
   "source": [
    "ev = estimator.evaluate(    \n",
    "          input_fn=get_input_fn(test_set,                          \n",
    "          num_epochs=1,                          \n",
    "          batch_size = 128,                          \n",
    "          shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 21.846708\n"
     ]
    }
   ],
   "source": [
    "loss_score = ev[\"loss\"]\n",
    "print(\"Loss: {0:f}\".format(loss_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    400.000000\n",
       "mean      22.625500\n",
       "std        9.572593\n",
       "min        5.000000\n",
       "25%       16.600000\n",
       "50%       21.400000\n",
       "75%       25.025000\n",
       "max       50.000000\n",
       "Name: medv, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[LABEL].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = estimator.predict(    \n",
    "         input_fn=get_input_fn(prediction_set,                          \n",
    "         num_epochs=1,                          \n",
    "         batch_size = 128,                          \n",
    "         shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: []\n"
     ]
    }
   ],
   "source": [
    "predictions = list(p[\"predictions\"] for p in itertools.islice(y, 6))\n",
    "print(\"Predictions: {}\".format(str(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: ['serving_default', 'regression']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from train/model.ckpt-6000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /var/folders/6_/8_x7k80s52vcfppnmvb31wxr0000gn/T/tmpuwn5w5id/from_estimator/temp-b'1609552565'/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "OUTDIR='./models'\n",
    "feature_spec = tf.feature_column.make_parse_example_spec(feature_cols);\n",
    "export_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec);\n",
    "estimator_path = estimator.export_saved_model(estimator_base_path, export_input_fn)\n",
    "imported = tf.saved_model.load(estimator_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
