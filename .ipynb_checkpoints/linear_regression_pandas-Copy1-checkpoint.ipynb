{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_n = pd.read_csv('/Users/wisdom/Downloads/boston_train/boston_train.csv').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_n = pd.read_csv('/Users/wisdom/Downloads/boston_train/boston_test.csv').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_set_n = pd.read_csv('/Users/wisdom/Downloads/boston_train/boston_predict.csv').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.35900e-02 7.50000e+01 2.95000e+00 4.28000e-01 7.02400e+00 1.58000e+01\n",
      "  5.40110e+00 2.52000e+02 1.83000e+01         nan         nan]\n",
      " [5.09017e+00 0.00000e+00 1.81000e+01 7.13000e-01 6.29700e+00 9.18000e+01\n",
      "  2.36820e+00 6.66000e+02 2.02000e+01         nan         nan]\n",
      " [1.26500e-01 2.50000e+01 5.13000e+00 4.53000e-01 6.76200e+00 4.34000e+01\n",
      "  7.98090e+00 2.84000e+02 1.97000e+01         nan         nan]\n",
      " [5.51500e-02 3.30000e+01 2.18000e+00 4.72000e-01 7.23600e+00 4.11000e+01\n",
      "  4.02200e+00 2.22000e+02 1.84000e+01         nan         nan]\n",
      " [8.15174e+00 0.00000e+00 1.81000e+01 7.00000e-01 5.39000e+00 9.89000e+01\n",
      "  1.72810e+00 6.66000e+02 2.02000e+01         nan         nan]\n",
      " [2.45220e-01 0.00000e+00 9.90000e+00 5.44000e-01 5.78200e+00 7.17000e+01\n",
      "  4.03170e+00 3.04000e+02 1.84000e+01         nan         nan]]\n"
     ]
    }
   ],
   "source": [
    "print(prediction_set_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "    X_train = df[:, :-3]\n",
    "    y_train = df[:,-3]    \n",
    "    return X_train, y_train\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = prepare_data(training_set_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = prepare_data(test_set_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.35870e-01 0.00000e+00 1.05900e+01 4.89000e-01 6.06400e+00 5.91000e+01\n",
      "  4.23920e+00 2.77000e+02 1.86000e+01]\n",
      " [8.66400e-02 4.50000e+01 3.44000e+00 4.37000e-01 7.17800e+00 2.63000e+01\n",
      "  6.47980e+00 3.98000e+02 1.52000e+01]\n",
      " [2.69380e-01 0.00000e+00 9.90000e+00 5.44000e-01 6.26600e+00 8.28000e+01\n",
      "  3.26280e+00 3.04000e+02 1.84000e+01]\n",
      " [5.30200e-02 0.00000e+00 3.41000e+00 4.89000e-01 7.07900e+00 6.31000e+01\n",
      "  3.41450e+00 2.70000e+02 1.78000e+01]\n",
      " [6.86000e-02 0.00000e+00 2.89000e+00 4.45000e-01 7.41600e+00 6.25000e+01\n",
      "  3.49520e+00 2.76000e+02 1.80000e+01]\n",
      " [1.42310e-01 0.00000e+00 1.00100e+01 5.47000e-01 6.25400e+00 8.42000e+01\n",
      "  2.25650e+00 4.32000e+02 1.78000e+01]\n",
      " [1.67600e-01 0.00000e+00 7.38000e+00 4.93000e-01 6.42600e+00 5.23000e+01\n",
      "  4.54040e+00 2.87000e+02 1.96000e+01]\n",
      " [4.30100e-02 8.00000e+01 1.91000e+00 4.13000e-01 5.66300e+00 2.19000e+01\n",
      "  1.05857e+01 3.34000e+02 2.20000e+01]\n",
      " [6.90500e-02 0.00000e+00 2.18000e+00 4.58000e-01 7.14700e+00 5.42000e+01\n",
      "  6.06220e+00 2.22000e+02 1.87000e+01]\n",
      " [2.17190e-01 0.00000e+00 1.05900e+01 4.89000e-01 5.80700e+00 5.38000e+01\n",
      "  3.65260e+00 2.77000e+02 1.86000e+01]\n",
      " [6.07600e-02 0.00000e+00 1.19300e+01 5.73000e-01 6.97600e+00 9.10000e+01\n",
      "  2.16750e+00 2.73000e+02 2.10000e+01]\n",
      " [4.03841e+00 0.00000e+00 1.81000e+01 5.32000e-01 6.22900e+00 9.07000e+01\n",
      "  3.09930e+00 6.66000e+02 2.02000e+01]\n",
      " [1.69020e-01 0.00000e+00 2.56500e+01 5.81000e-01 5.98600e+00 8.84000e+01\n",
      "  1.99290e+00 1.88000e+02 1.91000e+01]\n",
      " [5.26930e-01 0.00000e+00 6.20000e+00 5.04000e-01 8.72500e+00 8.30000e+01\n",
      "  2.89440e+00 3.07000e+02 1.74000e+01]\n",
      " [1.20482e+01 0.00000e+00 1.81000e+01 6.14000e-01 5.64800e+00 8.76000e+01\n",
      "  1.95120e+00 6.66000e+02 2.02000e+01]\n",
      " [3.16360e+00 0.00000e+00 1.81000e+01 6.55000e-01 5.75900e+00 4.82000e+01\n",
      "  3.06650e+00 6.66000e+02 2.02000e+01]\n",
      " [1.00080e-01 0.00000e+00 2.46000e+00 4.88000e-01 6.56300e+00 9.56000e+01\n",
      "  2.84700e+00 1.93000e+02 1.78000e+01]\n",
      " [2.15505e+00 0.00000e+00 1.95800e+01 8.71000e-01 5.62800e+00 1.00000e+02\n",
      "  1.51660e+00 4.03000e+02 1.47000e+01]\n",
      " [3.58400e-02 8.00000e+01 3.37000e+00 3.98000e-01 6.29000e+00 1.78000e+01\n",
      "  6.61150e+00 3.37000e+02 1.61000e+01]\n",
      " [1.35540e-01 1.25000e+01 6.07000e+00 4.09000e-01 5.59400e+00 3.68000e+01\n",
      "  6.49800e+00 3.45000e+02 1.89000e+01]\n",
      " [1.78667e+01 0.00000e+00 1.81000e+01 6.71000e-01 6.22300e+00 1.00000e+02\n",
      "  1.38610e+00 6.66000e+02 2.02000e+01]\n",
      " [9.37800e-02 1.25000e+01 7.87000e+00 5.24000e-01 5.88900e+00 3.90000e+01\n",
      "  5.45090e+00 3.11000e+02 1.52000e+01]\n",
      " [5.37200e-02 0.00000e+00 1.39200e+01 4.37000e-01 6.54900e+00 5.10000e+01\n",
      "  5.96040e+00 2.89000e+02 1.60000e+01]\n",
      " [9.96654e+00 0.00000e+00 1.81000e+01 7.40000e-01 6.48500e+00 1.00000e+02\n",
      "  1.97840e+00 6.66000e+02 2.02000e+01]\n",
      " [3.84970e+00 0.00000e+00 1.81000e+01 7.70000e-01 6.39500e+00 9.10000e+01\n",
      "  2.50520e+00 6.66000e+02 2.02000e+01]\n",
      " [4.75470e-01 0.00000e+00 9.90000e+00 5.44000e-01 6.11300e+00 5.88000e+01\n",
      "  4.00190e+00 3.04000e+02 1.84000e+01]\n",
      " [6.64200e-02 0.00000e+00 4.05000e+00 5.10000e-01 6.86000e+00 7.44000e+01\n",
      "  2.91530e+00 2.96000e+02 1.66000e+01]\n",
      " [4.01100e-02 8.00000e+01 1.52000e+00 4.04000e-01 7.28700e+00 3.41000e+01\n",
      "  7.30900e+00 3.29000e+02 1.26000e+01]\n",
      " [4.02020e-01 0.00000e+00 9.90000e+00 5.44000e-01 6.38200e+00 6.72000e+01\n",
      "  3.53250e+00 3.04000e+02 1.84000e+01]\n",
      " [4.52700e-02 0.00000e+00 1.19300e+01 5.73000e-01 6.12000e+00 7.67000e+01\n",
      "  2.28750e+00 2.73000e+02 2.10000e+01]\n",
      " [6.61700e-02 0.00000e+00 3.24000e+00 4.60000e-01 5.86800e+00 2.58000e+01\n",
      "  5.21460e+00 4.30000e+02 1.69000e+01]\n",
      " [6.41700e-02 0.00000e+00 5.96000e+00 4.99000e-01 5.93300e+00 6.82000e+01\n",
      "  3.36030e+00 2.79000e+02 1.92000e+01]\n",
      " [9.06800e-02 4.50000e+01 3.44000e+00 4.37000e-01 6.95100e+00 2.15000e+01\n",
      "  6.47980e+00 3.98000e+02 1.52000e+01]\n",
      " [1.04690e-01 4.00000e+01 6.41000e+00 4.47000e-01 7.26700e+00 4.90000e+01\n",
      "  4.78720e+00 2.54000e+02 1.76000e+01]\n",
      " [3.68940e-01 2.20000e+01 5.86000e+00 4.31000e-01 8.25900e+00 8.40000e+00\n",
      "  8.90670e+00 3.30000e+02 1.91000e+01]\n",
      " [1.71340e-01 0.00000e+00 1.00100e+01 5.47000e-01 5.92800e+00 8.82000e+01\n",
      "  2.46310e+00 4.32000e+02 1.78000e+01]\n",
      " [7.72990e-01 0.00000e+00 8.14000e+00 5.38000e-01 6.49500e+00 9.44000e+01\n",
      "  4.45470e+00 3.07000e+02 2.10000e+01]\n",
      " [5.40500e-01 2.00000e+01 3.97000e+00 5.75000e-01 7.47000e+00 5.26000e+01\n",
      "  2.87200e+00 2.64000e+02 1.30000e+01]\n",
      " [1.39600e-01 0.00000e+00 8.56000e+00 5.20000e-01 6.16700e+00 9.00000e+01\n",
      "  2.42100e+00 3.84000e+02 2.09000e+01]\n",
      " [7.61620e-01 2.00000e+01 3.97000e+00 6.47000e-01 5.56000e+00 6.28000e+01\n",
      "  1.98650e+00 2.64000e+02 1.30000e+01]\n",
      " [9.06500e-02 2.00000e+01 6.96000e+00 4.64000e-01 5.92000e+00 6.15000e+01\n",
      "  3.91750e+00 2.23000e+02 1.86000e+01]\n",
      " [1.31170e-01 0.00000e+00 8.56000e+00 5.20000e-01 6.12700e+00 8.52000e+01\n",
      "  2.12240e+00 3.84000e+02 2.09000e+01]\n",
      " [4.35710e-01 0.00000e+00 1.05900e+01 4.89000e-01 5.34400e+00 1.00000e+02\n",
      "  3.87500e+00 2.77000e+02 1.86000e+01]\n",
      " [1.41385e+00 0.00000e+00 1.95800e+01 8.71000e-01 6.12900e+00 9.60000e+01\n",
      "  1.74940e+00 4.03000e+02 1.47000e+01]\n",
      " [1.18123e+01 0.00000e+00 1.81000e+01 7.18000e-01 6.82400e+00 7.65000e+01\n",
      "  1.79400e+00 6.66000e+02 2.02000e+01]\n",
      " [7.02259e+00 0.00000e+00 1.81000e+01 7.18000e-01 6.00600e+00 9.53000e+01\n",
      "  1.87460e+00 6.66000e+02 2.02000e+01]\n",
      " [4.26131e+00 0.00000e+00 1.81000e+01 7.70000e-01 6.11200e+00 8.13000e+01\n",
      "  2.50910e+00 6.66000e+02 2.02000e+01]\n",
      " [2.31390e+00 0.00000e+00 1.95800e+01 6.05000e-01 5.88000e+00 9.73000e+01\n",
      "  2.38870e+00 4.03000e+02 1.47000e+01]\n",
      " [6.27390e-01 0.00000e+00 8.14000e+00 5.38000e-01 5.83400e+00 5.65000e+01\n",
      "  4.49860e+00 3.07000e+02 2.10000e+01]\n",
      " [1.17470e-01 1.25000e+01 7.87000e+00 5.24000e-01 6.00900e+00 8.29000e+01\n",
      "  6.22670e+00 3.11000e+02 1.52000e+01]\n",
      " [2.25971e+01 0.00000e+00 1.81000e+01 7.00000e-01 5.00000e+00 8.95000e+01\n",
      "  1.51840e+00 6.66000e+02 2.02000e+01]\n",
      " [4.22239e+00 0.00000e+00 1.81000e+01 7.70000e-01 5.80300e+00 8.90000e+01\n",
      "  1.90470e+00 6.66000e+02 2.02000e+01]\n",
      " [3.54800e-02 8.00000e+01 3.64000e+00 3.92000e-01 5.87600e+00 1.91000e+01\n",
      "  9.22030e+00 3.15000e+02 1.64000e+01]\n",
      " [8.19900e-02 0.00000e+00 1.39200e+01 4.37000e-01 6.00900e+00 4.23000e+01\n",
      "  5.50270e+00 2.89000e+02 1.60000e+01]\n",
      " [1.14320e-01 0.00000e+00 8.56000e+00 5.20000e-01 6.78100e+00 7.13000e+01\n",
      "  2.85610e+00 3.84000e+02 2.09000e+01]\n",
      " [1.34284e+00 0.00000e+00 1.95800e+01 6.05000e-01 6.06600e+00 1.00000e+02\n",
      "  1.75730e+00 4.03000e+02 1.47000e+01]\n",
      " [1.22472e+01 0.00000e+00 1.81000e+01 5.84000e-01 5.83700e+00 5.97000e+01\n",
      "  1.99760e+00 6.66000e+02 2.02000e+01]\n",
      " [2.19770e-01 0.00000e+00 6.91000e+00 4.48000e-01 5.60200e+00 6.20000e+01\n",
      "  6.08770e+00 2.33000e+02 1.79000e+01]\n",
      " [1.09600e-02 5.50000e+01 2.25000e+00 3.89000e-01 6.45300e+00 3.19000e+01\n",
      "  7.30730e+00 3.00000e+02 1.53000e+01]\n",
      " [1.28160e-01 1.25000e+01 6.07000e+00 4.09000e-01 5.88500e+00 3.30000e+01\n",
      "  6.49800e+00 3.45000e+02 1.89000e+01]\n",
      " [1.70040e-01 1.25000e+01 7.87000e+00 5.24000e-01 6.00400e+00 8.59000e+01\n",
      "  6.59210e+00 3.11000e+02 1.52000e+01]\n",
      " [2.63548e+00 0.00000e+00 9.90000e+00 5.44000e-01 4.97300e+00 3.78000e+01\n",
      "  2.51940e+00 3.04000e+02 1.84000e+01]\n",
      " [2.14090e-01 2.20000e+01 5.86000e+00 4.31000e-01 6.43800e+00 8.90000e+00\n",
      "  7.39670e+00 3.30000e+02 1.91000e+01]\n",
      " [4.41700e-02 7.00000e+01 2.24000e+00 4.00000e-01 6.87100e+00 4.74000e+01\n",
      "  7.82780e+00 3.58000e+02 1.48000e+01]\n",
      " [7.50260e-01 0.00000e+00 8.14000e+00 5.38000e-01 5.92400e+00 9.41000e+01\n",
      "  4.39960e+00 3.07000e+02 2.10000e+01]\n",
      " [1.36781e+01 0.00000e+00 1.81000e+01 7.40000e-01 5.93500e+00 8.79000e+01\n",
      "  1.82060e+00 6.66000e+02 2.02000e+01]\n",
      " [9.60400e-02 4.00000e+01 6.41000e+00 4.47000e-01 6.85400e+00 4.28000e+01\n",
      "  4.26730e+00 2.54000e+02 1.76000e+01]\n",
      " [1.40300e-01 2.20000e+01 5.86000e+00 4.31000e-01 6.48700e+00 1.30000e+01\n",
      "  7.39670e+00 3.30000e+02 1.91000e+01]\n",
      " [4.41780e-01 0.00000e+00 6.20000e+00 5.04000e-01 6.55200e+00 2.14000e+01\n",
      "  3.37510e+00 3.07000e+02 1.74000e+01]\n",
      " [3.44500e-02 8.25000e+01 2.03000e+00 4.15000e-01 6.16200e+00 3.84000e+01\n",
      "  6.27000e+00 3.48000e+02 1.47000e+01]\n",
      " [1.00840e-01 0.00000e+00 1.00100e+01 5.47000e-01 6.71500e+00 8.16000e+01\n",
      "  2.67750e+00 4.32000e+02 1.78000e+01]\n",
      " [8.70700e-02 0.00000e+00 1.28300e+01 4.37000e-01 6.14000e+00 4.58000e+01\n",
      "  4.09050e+00 3.98000e+02 1.87000e+01]\n",
      " [3.51140e-01 0.00000e+00 7.38000e+00 4.93000e-01 6.04100e+00 4.99000e+01\n",
      "  4.72110e+00 2.87000e+02 1.96000e+01]\n",
      " [1.10270e-01 2.50000e+01 5.13000e+00 4.53000e-01 6.45600e+00 6.78000e+01\n",
      "  7.22550e+00 2.84000e+02 1.97000e+01]\n",
      " [1.50100e-02 8.00000e+01 2.01000e+00 4.35000e-01 6.63500e+00 2.97000e+01\n",
      "  8.34400e+00 2.80000e+02 1.70000e+01]\n",
      " [9.51363e+00 0.00000e+00 1.81000e+01 7.13000e-01 6.72800e+00 9.41000e+01\n",
      "  2.49610e+00 6.66000e+02 2.02000e+01]\n",
      " [7.50300e-02 3.30000e+01 2.18000e+00 4.72000e-01 7.42000e+00 7.19000e+01\n",
      "  3.09920e+00 2.22000e+02 1.84000e+01]\n",
      " [1.11604e+01 0.00000e+00 1.81000e+01 7.40000e-01 6.62900e+00 9.46000e+01\n",
      "  2.12470e+00 6.66000e+02 2.02000e+01]\n",
      " [7.52601e+00 0.00000e+00 1.81000e+01 7.13000e-01 6.41700e+00 9.83000e+01\n",
      "  2.18500e+00 6.66000e+02 2.02000e+01]\n",
      " [2.73397e+00 0.00000e+00 1.95800e+01 8.71000e-01 5.59700e+00 9.49000e+01\n",
      "  1.52570e+00 4.03000e+02 1.47000e+01]\n",
      " [2.90900e-01 0.00000e+00 2.18900e+01 6.24000e-01 6.17400e+00 9.36000e+01\n",
      "  1.61190e+00 4.37000e+02 2.12000e+01]\n",
      " [9.33889e+00 0.00000e+00 1.81000e+01 6.79000e-01 6.38000e+00 9.56000e+01\n",
      "  1.96820e+00 6.66000e+02 2.02000e+01]\n",
      " [2.49800e-02 0.00000e+00 1.89000e+00 5.18000e-01 6.54000e+00 5.97000e+01\n",
      "  6.26690e+00 4.22000e+02 1.59000e+01]\n",
      " [1.22690e-01 0.00000e+00 6.91000e+00 4.48000e-01 6.06900e+00 4.00000e+01\n",
      "  5.72090e+00 2.33000e+02 1.79000e+01]\n",
      " [1.09590e-01 0.00000e+00 1.19300e+01 5.73000e-01 6.79400e+00 8.93000e+01\n",
      "  2.38890e+00 2.73000e+02 2.10000e+01]\n",
      " [8.01400e-02 0.00000e+00 5.96000e+00 4.99000e-01 5.85000e+00 4.15000e+01\n",
      "  3.93420e+00 2.79000e+02 1.92000e+01]\n",
      " [3.11300e-02 0.00000e+00 4.39000e+00 4.42000e-01 6.01400e+00 4.85000e+01\n",
      "  8.01360e+00 3.52000e+02 1.88000e+01]\n",
      " [5.82115e+00 0.00000e+00 1.81000e+01 7.13000e-01 6.51300e+00 8.99000e+01\n",
      "  2.80160e+00 6.66000e+02 2.02000e+01]\n",
      " [6.56650e-01 2.00000e+01 3.97000e+00 6.47000e-01 6.84200e+00 1.00000e+02\n",
      "  2.01070e+00 2.64000e+02 1.30000e+01]\n",
      " [7.90410e-01 0.00000e+00 9.90000e+00 5.44000e-01 6.12200e+00 5.28000e+01\n",
      "  2.64030e+00 3.04000e+02 1.84000e+01]\n",
      " [9.26600e-02 3.40000e+01 6.09000e+00 4.33000e-01 6.49500e+00 1.84000e+01\n",
      "  5.49170e+00 3.29000e+02 1.61000e+01]\n",
      " [1.77830e-01 0.00000e+00 9.69000e+00 5.85000e-01 5.56900e+00 7.35000e+01\n",
      "  2.39990e+00 3.91000e+02 1.92000e+01]\n",
      " [7.01300e-02 0.00000e+00 1.38900e+01 5.50000e-01 6.64200e+00 8.51000e+01\n",
      "  3.42110e+00 2.76000e+02 1.64000e+01]\n",
      " [4.12380e-01 0.00000e+00 6.20000e+00 5.04000e-01 7.16300e+00 7.99000e+01\n",
      "  3.21570e+00 3.07000e+02 1.74000e+01]\n",
      " [1.55757e+01 0.00000e+00 1.81000e+01 5.80000e-01 5.92600e+00 7.10000e+01\n",
      "  2.90840e+00 6.66000e+02 2.02000e+01]\n",
      " [1.32620e-01 0.00000e+00 8.56000e+00 5.20000e-01 5.85100e+00 9.67000e+01\n",
      "  2.10690e+00 3.84000e+02 2.09000e+01]\n",
      " [6.80117e+00 0.00000e+00 1.81000e+01 7.13000e-01 6.08100e+00 8.44000e+01\n",
      "  2.71750e+00 6.66000e+02 2.02000e+01]\n",
      " [1.28023e+01 0.00000e+00 1.81000e+01 7.40000e-01 5.85400e+00 9.66000e+01\n",
      "  1.89560e+00 6.66000e+02 2.02000e+01]\n",
      " [1.02330e+01 0.00000e+00 1.81000e+01 6.14000e-01 6.18500e+00 9.67000e+01\n",
      "  2.17050e+00 6.66000e+02 2.02000e+01]\n",
      " [3.58090e-01 0.00000e+00 6.20000e+00 5.07000e-01 6.95100e+00 8.85000e+01\n",
      "  2.86170e+00 3.07000e+02 1.74000e+01]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_predict = prediction_set_n[:, :-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.35900e-02 7.50000e+01 2.95000e+00 4.28000e-01 7.02400e+00 1.58000e+01\n",
      "  5.40110e+00 2.52000e+02 1.83000e+01]\n",
      " [5.09017e+00 0.00000e+00 1.81000e+01 7.13000e-01 6.29700e+00 9.18000e+01\n",
      "  2.36820e+00 6.66000e+02 2.02000e+01]\n",
      " [1.26500e-01 2.50000e+01 5.13000e+00 4.53000e-01 6.76200e+00 4.34000e+01\n",
      "  7.98090e+00 2.84000e+02 1.97000e+01]\n",
      " [5.51500e-02 3.30000e+01 2.18000e+00 4.72000e-01 7.23600e+00 4.11000e+01\n",
      "  4.02200e+00 2.22000e+02 1.84000e+01]\n",
      " [8.15174e+00 0.00000e+00 1.81000e+01 7.00000e-01 5.39000e+00 9.89000e+01\n",
      "  1.72810e+00 6.66000e+02 2.02000e+01]\n",
      " [2.45220e-01 0.00000e+00 9.90000e+00 5.44000e-01 5.78200e+00 7.17000e+01\n",
      "  4.03170e+00 3.04000e+02 1.84000e+01]]\n"
     ]
    }
   ],
   "source": [
    "print(X_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 9) (400,) (6, 9)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, X_predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [tf.feature_column.numeric_column('x', shape=X_train.shape[1:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NumericColumn(key='x', shape=(9,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "print(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'train_n', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe9c603bd90>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "estimator = tf.estimator.LinearRegressor(feature_columns=feature_columns, model_dir=\"train_n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_fn(data_df, label_df, num_epochs=None, batch_size=128, shuffle=True, steps=1000):\n",
    "    def input_fn():\n",
    "        ds = tf.data.Dataset.from_tensor_slices(({\"x\": data_df}, label_df)) if label_df is not None else tf.data.Dataset.from_tensor_slices(({\"x\": data_df}))\n",
    "        if shuffle:\n",
    "            ds = ds.shuffle(steps)\n",
    "        ds = ds.batch(batch_size)\n",
    "        return ds\n",
    "    return input_fn     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from train_n/model.ckpt-186\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 186 into train_n/model.ckpt.\n",
      "INFO:tensorflow:loss = 99.647705, step = 186\n",
      "INFO:tensorflow:Saving checkpoints for 190 into train_n/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 80.22194.\n"
     ]
    }
   ],
   "source": [
    "train = estimator.train(input_fn=get_input_fn(X_train, y_train, shuffle=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-01-03T19:57:26Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from train_n/model.ckpt-190\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2021-01-03-19:57:27\n",
      "INFO:tensorflow:Saving dict for global step 190: average_loss = 50.994217, global_step = 190, label/mean = 22.08, loss = 50.994217, prediction/mean = 22.624155\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 190: train_n/model.ckpt-190\n",
      "{'average_loss': 50.994217, 'label/mean': 22.08, 'loss': 50.994217, 'prediction/mean': 22.624155, 'global_step': 190}\n"
     ]
    }
   ],
   "source": [
    "ev = estimator.evaluate(input_fn=get_input_fn(X_test, y_test, shuffle=False))\n",
    "print(ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 50.994217\n"
     ]
    }
   ],
   "source": [
    "loss_score = ev[\"loss\"]\n",
    "print(\"Loss: {0:f}\".format(loss_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = estimator.predict(input_fn=get_input_fn(X_predict, None, shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.937294\n",
      "21.649946\n",
      "27.398323\n",
      "25.803082\n",
      "20.206217\n",
      "21.798332\n"
     ]
    }
   ],
   "source": [
    "pred_dicts = list(estimator.predict(input_fn=get_input_fn(X_predict, None, shuffle=False)))\n",
    "clear_output()\n",
    "for pred in pred_dicts:\n",
    "    print(pred[\"predictions\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from train_n/model.ckpt-190\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "30.937294\n",
      "21.649946\n",
      "27.398323\n",
      "25.803082\n",
      "20.206217\n",
      "21.798332\n"
     ]
    }
   ],
   "source": [
    "pred_dicts = list(y)\n",
    "for pred in pred_dicts:\n",
    "    print(pred[\"predictions\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: ['serving_default', 'regression']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from train_n/model.ckpt-190\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /var/folders/6_/8_x7k80s52vcfppnmvb31wxr0000gn/T/tmpdyyytqr1/from_estimator/temp-b'1609703847'/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "tmpdir = tempfile.mkdtemp()\n",
    "estimator_base_path = os.path.join(tmpdir, 'from_estimator')\n",
    "feature_spec = tf.feature_column.make_parse_example_spec(feature_columns);\n",
    "export_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec);\n",
    "estimator_path = estimator.export_saved_model(estimator_base_path, export_input_fn)\n",
    "imported = tf.saved_model.load(estimator_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    x_bytes =tf.io.serialize_tensor(x)\n",
    "    example = tf.train.Example()\n",
    "    example.features.feature[\"x\"].bytes_list.value.extend([x_bytes.numpy()])\n",
    "    return imported.signatures[\"predict\"](\n",
    "    examples=tf.constant([example.SerializeToString()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": " Name: <unknown>, Key: x, Index: 0.  Data types don't match. Data type: string but expected type: float\n\t [[node ParseExample/ParseExample (defined at /Users/wisdom/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1751) ]] [Op:__inference_pruned_3204]\n\nFunction call stack:\npruned\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-477ecc992046>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-110-6dea623fc06a>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mexample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbytes_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_bytes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     return imported.signatures[\"predict\"](\n\u001b[0;32m----> 6\u001b[0;31m     examples=tf.constant([example.SerializeToString()]))\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  Name: <unknown>, Key: x, Index: 0.  Data types don't match. Data type: string but expected type: float\n\t [[node ParseExample/ParseExample (defined at /Users/wisdom/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1751) ]] [Op:__inference_pruned_3204]\n\nFunction call stack:\npruned\n"
     ]
    }
   ],
   "source": [
    "print(predict(X_predict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
